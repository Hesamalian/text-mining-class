{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining of BBC News Data\n",
    "\n",
    "## Part 3: Document Clustering and Topic Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "text_filepaths = sorted(Path(\"bbc\").glob(\"*/*.txt\"))\n",
    "categories = [p.parent.name for p in text_filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    input=\"filename\", encoding=\"utf-8\", decode_error=\"ignore\",\n",
    "    min_df=5, max_df=0.7)\n",
    "\n",
    "tfidf_docs = tfidf_vectorizer.fit_transform(text_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, n_init=1).fit(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "\n",
    "- Run the previous clustering a second time, what do you observe?\n",
    "- Could you suggest why this is the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "- Use the array of weights of the center of the first cluster (`kmeans.cluster_centers_[0]`) and the feature names from the vectorizer to print the top 10 most important words of that cluster.\n",
    "\n",
    "- What is the main topic of that cluster centroid?\n",
    "\n",
    "Hint: feel free to use a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook_solutions/cluster_weights.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Quality of the K-Means Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_predictions = kmeans.predict(tfidf_docs)\n",
    "len(kmeans_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_predictions[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "adjusted_rand_score(kmeans_predictions, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Adjusted Rand Index** (ARI) considers all the possible pairs in the dataset and count the number of pairs that should be in the same cluster, the number and the numbers of pairs that should be assigned different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score([0, 1, 1, 0], [\"a\", \"b\", \"b\", \"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score([2, 0, 0, 2], [\"a\", \"b\", \"b\", \"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score([1, 1, 0, 0], [\"a\", \"b\", \"b\", \"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score([1, 0, 0, 2], [\"a\", \"b\", \"b\", \"a\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some (supervised) clustering metrics:\n",
    "    \n",
    "- Adjusted Rand Index\n",
    "- Adjusted / Normalized Mutual Information\n",
    "- V-measure (homegeneity and completeness)\n",
    "\n",
    "When we don't have ground truth labels (which is most often the case, otherwise why not use a supervised classifier?), there is no single unique best way to quantify cluster quality. One could use the following metrics but each of them makes different assumptions on the question of what is a \"good\" clustering result:\n",
    "\n",
    "- Measure inter or intra cluster average / min / max distances (euclidean, cosine, or custom metric).\n",
    "- Measure clustering stability when across resampling dataset and when adding small perturbations to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**\n",
    "\n",
    "- Find the documentation of clustering metrics on the scikit-learn.org documentation;\n",
    "- What is the meaning of homogeneity and completeness;\n",
    "- On a toy dataset with only 4, and 2 \"true\" clustering classes, find a clustering that is homogeneous but not complete and the converse;\n",
    "- Compute the homogneity, completness and V-measure score for the results of the KMeans algorithm above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebook_solutions/homogeneity_vs_completeness.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster Clustering with Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "rp_kmeans = make_pipeline(GaussianRandomProjection(n_components=500),\n",
    "                          KMeans(n_clusters=5, n_init=10))\n",
    "rp_kmeans_predictions = rp_kmeans.fit_predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(rp_kmeans_predictions, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "    \n",
    "- Try to reduce the dimension further, what do you observe?\n",
    "- What is the number of tunable parameters of the KMeans model in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd_kmeans = make_pipeline(TruncatedSVD(n_components=50),\n",
    "                           KMeans(n_clusters=5, n_init=10))\n",
    "svd_kmeans_predictions = svd_kmeans.fit_predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(svd_kmeans_predictions, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "- Compute the homogeneity and completeness scores for this pipeline;\n",
    "- Change the parameter `n_clusters`, how can you explain the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "\n",
    "- How text clustering can help datascientists?\n",
    "- What are some \"real word\" applications of unsupervised text clustering?\n",
    "- What is the main limitation of the use of clustering when trying to organize documents by topics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10, max_iter=15,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.).fit(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def print_components(components, feature_names, n=15, format=\"compact\"):\n",
    "    for i, component in enumerate(components):\n",
    "        df = pd.DataFrame({\"word\": feature_names, \"weight\": component})\n",
    "        top = df.nlargest(n, \"weight\")\n",
    "        if format == \"compact\":\n",
    "            print(f\"Topic #{i}: {', '.join(top['word'])}\")\n",
    "        else:\n",
    "            print(f\"Topic #{i}:\")\n",
    "            print(top)\n",
    "            print()\n",
    "                  \n",
    "print_components(lda.components_, feature_names, format=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained, the Latent Dirichlet Allocation model can infer the probability distribution of each topic for either old or new documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_docs = lda.transform(tfidf_docs)\n",
    "lda_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_docs[:5].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=10).fit(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_components(nmf.components_, feature_names, format=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF can also embed the documents in its own latent space but the result cannot be directly interpreted as a probablistic model of topics as is the case for LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_docs = nmf.transform(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_docs[:5].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**\n",
    "\n",
    "- Use `TruncatedSVD(n_components=10)` and print most weighted words for each components as we did for LDA and NMF.\n",
    "- Can it be used as a topic model?\n",
    "- Look at the 10 smallers weights for LDA, NMF and SVD. What different do you observer?\n",
    "- Transform the TF-IDF documents in SVD space and look at the first 5 documents. What do you observe?\n",
    "- How would you define the difference between a \"topic\" dimension and other kinds of \"latent\" dimensions such as the one extracted by Singular Value Decomposition?\n",
    "- What are applications for topic models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.7",
   "language": "python",
   "name": "python-3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
